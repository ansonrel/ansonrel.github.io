<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><link rel="canonical" href="https://example.com/start/modules/03_metric_module/" />
      <link rel="shortcut icon" href="../../../img/favicon.ico" />
    <title>Metric modules - Omnibenchmark</title>
    <link rel="stylesheet" href="../../../css/theme.css" />
    <link rel="stylesheet" href="../../../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/styles/github.min.css" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "Metric modules";
        var mkdocs_page_input_path = "start/modules/03_metric_module.md";
        var mkdocs_page_url = "/start/modules/03_metric_module/";
      </script>
    
    <script src="../../../js/jquery-3.6.0.min.js" defer></script>
    <!--[if lt IE 9]>
      <script src="../../../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/highlight.min.js"></script>
      <script>hljs.initHighlightingOnLoad();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href="../../.." class="icon icon-home"> Omnibenchmark
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../01_landing/">Motivation</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../about/">About</a>
                </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../..">Omnibenchmark</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../../.." class="icon icon-home" alt="Docs"></a> &raquo;</li>
      <li>Metric modules</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="metric-modules">Metric modules</h1>
<p>A metric module imports method result datasets and runs one evaluation on them. Evaluation results are added to a <a href="https://renku.readthedocs.io/en/latest/topic-guides/data.html#">renku dataset</a>, that can be summarized and explored in an {ref}<code>omnibenchmark bettr dashboard &lt;section-output&gt;</code>. Benchmark specific requirements like file formats, types and prefixes can be checked at the <a href="https://omnibenchmark.pages.uzh.ch/omni_dash/index.html">omnibenchmark webside</a>. Usually a metric module contains two workflows, one to evaluate the results and one to generate the <strong><code>metric info file</code></strong>. Most metric modules contain 5 main files:</p>
<h2 id="1-the-configyaml-file">1. The config.yaml file</h2>
<p>All information about the module are specified in the {ref}<code>config.yaml file &lt;section-config&gt;</code>:</p>
<pre><code class="language-yaml">---
data:
    name: &quot;metric name&quot;
    title: &quot;metric title&quot;
    description: &quot;Short description of the metric&quot;
    keywords: [&quot;MODULE_KEY&quot;]
script: &quot;path/to/module_script&quot;
benchmark_name: &quot;OMNIBENCHMARK_TYPE&quot;
inputs:
    keywords: [&quot;INPUT_KEY1&quot;, &quot;INPUT_KEY2&quot;]
    files: [&quot;input_file_name1&quot;, &quot;input_file_name2&quot;]
    prefix:
        input_file_name1: &quot;_INPUT1_&quot;
        input_file_name2: &quot;_INPUT2_&quot;
outputs:
    files:
        metric_result: 
            end: &quot;FILE1_END&quot;
</code></pre>
<p>Entries in capital letters depend on the specifications at the <a href="https://omnibenchmark.pages.uzh.ch/omni_dash/index.html">omnibenchmark webside</a>.</p>
<h2 id="2-the-info_configyaml-file">2. The info_config.yaml file</h2>
<p>All information about the module are specified in the {ref}<code>config.yaml file &lt;section-config&gt;</code>:</p>
<pre><code class="language-yaml">---
data:
    name: &quot;metric name&quot;
script: &quot;src/generate_metric_info.py&quot;
benchmark_name: &quot;OMNIBENCHMARK_TYPE&quot;
outputs:
    files:
        metric_info: 
            end: &quot;json&quot;
    file_mapping:
        mapping1:
          output_files:
            metric_info: &quot;path/to/metric_name_info.json&quot;
</code></pre>
<h2 id="3-the-run_workflowpy-file">3. The run_workflow.py file</h2>
<p>This file is to generate, run and update the modules dataset and workflow. A most basic script to do so looks like this:</p>
<pre><code class="language-python"># Load modules
from omnibenchmark.utils.build_omni_object import get_omni_object_from_yaml
from omnibenchmark.renku_commands.general import renku_save

# Build an OmniObject from the config.yaml file
omni_obj = get_omni_object_from_yaml('src/config.yaml')

# Import and update inputs/parameter and update object accordingly 
omni_obj.update_object()
renku_save()

# Create the output dataset
omni_obj.create_dataset()
renku_save()

## Run and update the workflow on all inputs and parameter combinations
omni_obj.run_renku()
renku_save()

## Add files to output dataset
omni_obj.update_result_dataset()
renku_save()

###################### Generate info file ######################
# Build an OmniObject from the info_config.yaml file
omni_info = get_omni_object_from_yaml('src/info_config.yaml')
omni_info.wflow_name = &quot;metric_info&quot;

## Run and update workflow
omni_info.run_renku()
renku_save()

## Update output dataset 
omni_info.update_result_dataset()
renku_save()
</code></pre>
<h2 id="4-the-module-script">4. The module script</h2>
<p>This is the script to load the dataset and to convert its files into the expected format.
Omnibenchmark accepts any kind of script and its maintenance and content is up to the module author.
Omnibenchmark calls this script from the command line. If you use another language than R, Python, Julia or bash, specify the interpreter to use in the corresponding field of the {ref}<code>config.yaml file &lt;section-config&gt;</code> file.</p>
<p>:::note
All input and output files and if applicable parameter need to be parsed from the command line in the format:
<code>--ARGUMENT_NAME ARGUMENT_VALUE</code>
:::</p>
<p>In Python <a href="https://pypi.org/project/argparse/">argparse</a> can be used to parse command arguments like this:</p>
<pre><code class="language-python"># Load module
import argparse

# Get command line arguments and store them in args
parser=argparse.ArgumentParser()
parser.add_argument('--argument_name', help='Description of the argument')
args=parser.parse_args()

# Call the argument
arg1 = args.argument_name

</code></pre>
<p>In R we recommend to use the <a href="https://cran.r-project.org/web/packages/optparse/index.html">optparse</a> package:</p>
<pre><code class="language-r"># Load package
library(optparse)

# Get list with command line arguments by name
option_list = list(
    make_option(c(&quot;--argument_name&quot;), type=&quot;character&quot;, default=NULL, 
              help=&quot;Description of the argument&quot;, metavar=&quot;character&quot;)
); 

opt_parser = OptionParser(option_list=option_list);
opt = parse_args(opt_parser);

# An useful error if the argument is missing
if (is.null(opt$argument_name)){
  print_help(opt_parser)
  stop(&quot;Argument_name needs to be specified, but is missing.n&quot;, call.=FALSE)
}

# Call the argument
arg1 &lt;- opt$argument_name
</code></pre>
<h2 id="5-the-generate_metric_infopy-file">5. The generate_metric_info.py file</h2>
<p>This file could also be written in R or any other language. It should return a json file with the below fields with the metrics information.</p>
<pre><code class="language-python">import argparse
import json

parser=argparse.ArgumentParser()
parser.add_argument('--metric_info', help='Path to the metric info json file')
args=parser.parse_args()

metric_info = {
    'flip': False,
    'max': 1,
    'min': 0,
    'group': &quot;METRIC_GROUP&quot;,
    'name': &quot;metric_name&quot;,
    'input': &quot;metric_input_type&quot;
}

with open(args.metric_info, &quot;w&quot;) as fp:
    json.dump(metric_info , fp, indent=3) 
</code></pre>
              
            </div>
          </div><footer>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
    
  </span>
</div>
    <script>var base_url = '../../..';</script>
    <script src="../../../js/theme_extra.js" defer></script>
    <script src="../../../js/theme.js" defer></script>
      <script src="../../../search/main.js" defer></script>
    <script defer>
        window.onload = function () {
            SphinxRtdTheme.Navigation.enable(true);
        };
    </script>

</body>
</html>
